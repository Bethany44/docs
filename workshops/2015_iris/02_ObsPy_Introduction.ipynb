{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-image:url(images/meschede-seismic-waves.png); padding: 10px 30px 20px 30px; background-size:cover; background-opacity:50%; border-radius:5px\">\n",
    "<p style=\"float:right; margin-top:20px; padding: 20px 20px 0px 20px; background:rgba(255,255,255,0.6); border-radius:10px;\">\n",
    "<img width=\"400px\" src=images/obspy_logo_full_524x179px.png?raw=true>\n",
    "\n",
    "</p>\n",
    "\n",
    "<h1 style=\"color:#999\">IRIS-EarthScope Short Course</h1>\n",
    "<h5 style=\"color:#FFF\">Bloomington/IN, August 2015</h5>\n",
    "<br/>\n",
    "<h2 style=\"color:#EEE\">Python/ObsPy Introduction</h2>\n",
    "<br/>\n",
    "\n",
    "</div>\n",
    "<div align=\"right\">image by Matthias Meschede</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ObsPy Introduction\n",
    "\n",
    "In this *very* short introduction to ObsPy we will see how we can start from scratch to acquire time series data (aka waveforms) of the ground shaking resulting from earthquakes, recorded at seismometer stations. Many global seismometer recordings are free to be downloaded by everybody. We will also see how these data can be handled in Python using the ObsPy framework.\n",
    "\n",
    "We will:\n",
    "1. fetch information on earthquakes (aka events) hosted by international data centers\n",
    "2. fetch information on seismometer stations that recorded a particular earthquake\n",
    "3. fetch waveform data of the earthquake waves recorded at that station\n",
    "4. convert the raw recorded data to physical units (aka instrument correction)\n",
    " \n",
    "Again, please execute the following cell, it contains a few adjustments to the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "from __future__ import print_function\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = 12, 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Event Metadata\n",
    "\n",
    " * several different protocols are implemented in ObsPy to connect to all important seismological data centers\n",
    " * the most important protocol are [FDSN web services](http://docs.obspy.org/packages/obspy.fdsn.html) (other protocols work very similar)\n",
    " * the \"[`get_events()`](http://docs.obspy.org/packages/autogen/obspy.fdsn.client.Client.get_events.html)\" method has many ways to restrict the search results (time, geographic, magnitude, ..)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from obspy.fdsn import Client\n",
    "\n",
    "# IRIS is the biggest seismological data center, based in the US\n",
    "client = Client(\"IRIS\")\n",
    "\n",
    "catalog = client.get_events(minmagnitude=8.5, starttime=\"2010-01-01\")\n",
    "\n",
    "print(catalog)\n",
    "catalog.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- event/earthquake metadata is bundled in a **`Catalog`** object, which is a collection (~list) of **`Event`** objects\n",
    "- `Event` objects are again collections of other resources (origins, magnitudes, picks, ...)\n",
    "- the nested ObsPy Event class structure (Catalog/Event/Origin/Magnitude/FocalMechanism/...) is closely modelled after [QuakeML](https://quake.ethz.ch/quakeml) (the international standard exchange format for event metadata)\n",
    "<img src=\"images/Event.svg\" width=100%>\n",
    "<img src=\"images/quakeml_light.png\" width=100%>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(catalog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "event = catalog[1]\n",
    "print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# you can use Tab-Completion to see what attributes/methods the event object has:\n",
    "event.\n",
    "origin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * local files can be read using the [`readEvents()`](http://docs.obspy.org/packages/autogen/obspy.core.event.readEvents.html) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from obspy import readEvents\n",
    "\n",
    "catalog2 = readEvents(\"./data/events_unterhaching.xml\")\n",
    "print(catalog2)\n",
    "\n",
    "# these events contain picks, too\n",
    "print(catalog2[0].picks[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Station Metadata\n",
    "\n",
    " * again, several different protocols are implemented in ObsPy to connect to all important seismological data centers\n",
    " * the most important protocol are [FDSN web services](http://docs.obspy.org/packages/obspy.fdsn.html) (other protocols work similar)\n",
    " * the \"[`get_stations()`](http://docs.obspy.org/packages/autogen/obspy.fdsn.client.Client.get_stations.html)\" method has many ways to restrict the search results (time, geographic, station names, ..)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t = event.origins[0].time\n",
    "print(t)\n",
    "\n",
    "inventory = client.get_stations(\n",
    "    network=\"TA\",\n",
    "    starttime=t, endtime=t+10)\n",
    "\n",
    "print(inventory)\n",
    "inventory.plot(projection=\"local\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- station metadata is bundled in an **`Inventory`** object, which is a collection (~list) of **`Network`** objects, ...\n",
    "- the nested ObsPy Inventory class structure (Inventory/Network/Station/Channel/Response/...) is closely modelled after [FDSN StationXML](http://www.fdsn.org/xml/station/) (the international standard exchange format for station metadata)\n",
    "- `Network` objects are again collections of `Station` objects, which are collections of `Channel` objects\n",
    "\n",
    "<img src=\"images/Inventory.svg\" width=100%>\n",
    "<img src=\"images/stationxml_light.png\" width=100%>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# let's request full detail metadata for one particular station\n",
    "inventory = client.get_stations(network=\"TA\", station=\"S36A\", level=\"response\")\n",
    "\n",
    "# when searching for many available stations response information is not included by default,\n",
    "# because of the huge size. we explicitly need to specify that we want response information included\n",
    "print(inventory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "network = inventory[0]\n",
    "print(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "station = network[0]\n",
    "print(station)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "station = station.select(channel=\"BH*\")\n",
    "print(station)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "channel = station[0]\n",
    "print(channel)\n",
    "print(channel.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# you can use Tab-Completion to see what attributes/methods the inventory object has:\n",
    "inventory.\n",
    "channel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * local files can be read using the [`read_inventory()`](http://docs.obspy.org/packages/autogen/obspy.station.inventory.read_inventory.html) function.\n",
    " * filetype is autodetected (but many real-world StationXML files do not adhere to the official schema, explicitly specify `format=\"STATIONXML\"` in that case!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from obspy import read_inventory\n",
    "\n",
    "inventory2 = read_inventory(\"./data/station_uh1.xml\", format=\"STATIONXML\")\n",
    "print(inventory2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Waveform Data (seismometer time series)\n",
    "\n",
    " * again, several different protocols are implemented in ObsPy to connect to all important seismological data centers\n",
    " * also, local files in all important exchange formats can be read\n",
    " * the most important protocol are [FDSN web services](http://docs.obspy.org/packages/obspy.fdsn.html) (other protocols work similar)\n",
    " * real time data can be accessed using [`obspy.seedlink`](http://docs.obspy.org/packages/obspy.seedlink.html)\n",
    " * the \"[`get_waveforms()`](http://docs.obspy.org/packages/autogen/obspy.fdsn.client.Client.get_waveforms.html)\" method needs the unique identification of the station (network, station, location and channel codes) and a time range (start time, end time) of requested data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stream = client.get_waveforms(network=\"TA\", station=\"S36A\",\n",
    "                              location=\"*\", channel=\"BH*\",\n",
    "                              starttime=t+10*60, endtime=t+70*60)\n",
    "\n",
    "# for functions/methods that need a fixed set of parameters,\n",
    "# we usually omit the parameter names and specify them in the expected order\n",
    "# Note that new timestamp objects can be created by\n",
    "# adding/subtracting seconds to/from an existing timestamp object.\n",
    "# (for details search the ObsPy documentation pages for \"UTCDateTime\")\n",
    "stream = client.get_waveforms(\"TA\", \"S36A\", \"*\", \"BH*\", t+10*60, t+70*60)\n",
    "\n",
    "print(stream)\n",
    "stream.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the nested ObsPy Inventory class structure (Inventory/Station/Channel/Response/...) is closely modelled after [FDSN StationXML](http://www.fdsn.org/xml/station/) (the international standard exchange format for station metadata)\n",
    "\n",
    "- waveform data is bundled in a **`Stream`** object, which is a collection (~list) of **`Trace`** objects\n",
    "- **`Trace`** objects consist of one single, contiguous waveform data block (i.e. regularly spaced time series, no gaps)\n",
    "- **`Trace`** objects consist of two attributes:\n",
    "  - **`trace.data`** (the raw time series as an [**`numpy.ndarray`**](http://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html)) and..\n",
    "  - **`trace.stats`** (metainformation needed to interpret the raw sample data)\n",
    "\n",
    "<img src=\"images/Stream_Trace.svg\" width=90%>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trace = stream[0]\n",
    "# trace.data is the numpy array with the raw samples\n",
    "print(trace.data)\n",
    "print(trace.data[20:30])\n",
    "# arithmetic operations on the data\n",
    "print(trace.data[20:30] / 223.5)\n",
    "# using attached numpy methods\n",
    "print(trace.data.mean())\n",
    "# pointers to the array in memory can be passed to C/Fortran routines from inside Python!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# trace.stats contains the basic metadata identifying the trace\n",
    "print(trace)\n",
    "print(trace.stats)\n",
    "print(trace.stats.sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# many convenience routines are attahed to Stream/Trace, use Tab completion\n",
    "stream."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * local files can be read using the [`read()`](http://docs.obspy.org/packages/autogen/obspy.core.stream.read.html) function.\n",
    " * filetype is autodetected (but can be manually specified to skip autodetection for speed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from obspy import read\n",
    "\n",
    "stream2 = read(\"./data/waveforms_uh1_eh?.mseed\")\n",
    "print(stream2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Converting raw seismometer recordings to physical units (aka instrument correction)\n",
    "\n",
    " * for this we need to combine the raw waveform data of the recording system (seismometer, digitizer) with the metadata on its amplitude and phase response (the instrument response)\n",
    " * these information are kept separate for various practical and technical reasons (space in storage and streaming, correcting of errors made in the metadata, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# first, let's have a look at this channel's instrument response\n",
    "channel.plot(min_freq=1e-4);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we already have fetched the station metadata,\n",
    "# including every piece of information down to the instrument response\n",
    "\n",
    "# let's make on a copy of the raw data, to be able to compare afterwards\n",
    "stream_corrected = stream.copy()\n",
    "\n",
    "# attach the instrument response to the waveforms..\n",
    "stream_corrected.attach_response(inventory)\n",
    "\n",
    "# and convert the data to ground velocity in m/s,\n",
    "# taking into account the specifics of the recording system\n",
    "stream_corrected.remove_response(water_level=10, output=\"VEL\")\n",
    "\n",
    "stream[0].plot()\n",
    "stream_corrected[0].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ObsPy has much more functionality, check it out on the ObsPy documentation pages at http://docs.obspy.org.\n",
    "\n",
    " * many, many convenience routines attached to `Stream`/`Trace`, `Catalog`/`Event`/.., `Inventory`/... for easy manipulation\n",
    " * filtering, detrending, demeaning, rotating, resampling, ...\n",
    " * array analysis, cross correlation routines, event detection, ...\n",
    " * estimate travel times and [plot ray paths](http://docs.obspy.org/tutorial/code_snippets/travel_time.html#body-wave-ray-paths) of seismic phases for specified source/receiver combinations\n",
    " * command line utilities (`obspy-print`, `obspy-plot`, `obspy-scan`, ...)\n",
    " * ...\n",
    " \n",
    " <img src=\"images/collage.png\" width=100%>\n",
    " \n",
    " ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automated Data Fetching/Processing Example\n",
    "\n",
    "This example prepares instrument corrected waveforms, 30 seconds around expected P arrival for a epicentral range of 30-40 degrees for any TA station/earthquake combination with magnitude larger 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from obspy.taup import TauPyModel\n",
    "from obspy.core.util.geodetics import gps2DistAzimuth, kilometer2degrees\n",
    "\n",
    "model = TauPyModel(model=\"iasp91\")\n",
    "\n",
    "catalog = client.get_events(starttime=\"2009-001\", endtime=\"2012-001\", minmagnitude=7)\n",
    "print(catalog)\n",
    "\n",
    "network = \"TA\"\n",
    "minradius = 30\n",
    "maxradius = 40\n",
    "phase = \"P\"\n",
    "\n",
    "for event in catalog:\n",
    "    origin = event.origins[0]\n",
    "    \n",
    "    try:\n",
    "        inventory = client.get_stations(network=network,\n",
    "                                        startbefore=origin.time, endafter=origin.time,\n",
    "                                        longitude=origin.longitude, latitude=origin.latitude,\n",
    "                                        minradius=minradius, maxradius=maxradius)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    print(event)\n",
    "\n",
    "    for station in inventory[0][:3]:\n",
    "        distance, _, _ = gps2DistAzimuth(origin.latitude, origin.longitude,\n",
    "                                         station.latitude, station.longitude)\n",
    "        distance = kilometer2degrees(distance / 1e3)\n",
    "        arrivals = model.get_travel_times(origin.depth / 1e3, distance,\n",
    "                                          phase_list=[phase])\n",
    "        traveltime = arrivals[0].time\n",
    "        arrival_time = origin.time + traveltime\n",
    "        \n",
    "        st = client.get_waveforms(network, station.code, \"*\", \"BH*\",\n",
    "                                  arrival_time - 200, arrival_time + 200,\n",
    "                                  attach_response=True)\n",
    "        st.remove_response(water_level=10, output=\"VEL\")\n",
    "        st.filter(\"lowpass\", freq=1)\n",
    "        st.trim(arrival_time - 10, arrival_time + 20)\n",
    "        st.plot()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Problems? Questions?\n",
    "\n",
    " - [ObsPy Documentation](http://docs.obspy.org/) (use the search)\n",
    " - Use IPython tab completion\n",
    " - Use interactive IPython help (e.g. after import type: `readEvents?`)\n",
    " - **Ask!**\n",
    " \n",
    "a) Read the event metadata from local file \"`./data/events_unterhaching.xml`\". Print the catalog summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Take one event out of the catalog. Print its summary. You can see, there is information included on picks set for the event. Print the information of at least one pick that is included in the event metadata. We now know one station that recorded the event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " c) Save the origin time of the event in a new variable. Download waveform data for the station around the time of the event (e.g. 10 seconds before and 20 seconds after), connecting to the FDSN server at the observatory at \"`http://erde.geophysik.uni-muenchen.de`\" (or read from local file `./data/waveforms_uh1_eh.mseed`). Put a \"`*`\" wildcard as the third (and last) letter of the channel code to download all three components (vertical, north, east). Plot the waveform data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Download station metadata for this station including the instrument response information (using the same client, or read it from file `./data/station_uh1.xml`). Attach the response information to the waveforms and remove the instrument response from the waveforms. Plot the waveforms again (now in ground velocity in m/s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) The peak ground velocity (PGV) is an important measure to judge possible effects on buildings. Determine the maximum value (absolute, whether positive or negative!) of either of the two horizontal components' data arrays (\"N\", \"E\"). You can use Python's builtin \"`max()`\" and \"`abs()`\" functions. For your information, ground shaking (in the frequency ranges of these very close earthquakes) can become perceptible to humans at above 0.5-1 mm/s, damage to buildings can be safely excluded for PGV values not exceeding 3 mm/s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
